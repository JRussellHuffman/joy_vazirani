<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <title>Joy Vazirani</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@100;200;300;400;600&display=swap" rel="stylesheet">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script type="text/javascript">
    $( document ).ready(function() {
        $('input[name="type_text"]').bind('keyup blur',function(){
            var node = $(this);
            node.val(node.val().replace(/[^a-zA-Z ]/g,'') ); }
        );

        $('input[name="type_text"]').keyup(function(){
          // console.log($(this).val());
          if (event.keyCode != 32 && (event.keyCode < 65 || event.keyCode > 90)) {
            flashNotSupported();
          } else {
            populateText($(this).val());
          }

        });
    });

    function populateText(key){
      $(".output_container").empty();
      for (var i = 0; i < key.length; i++) {
          if (key.charAt(i) == " ") {
             // $(".output_container").append('<img style="top:'+i*10+'px;" class="waveform" id="space" src="letters/space_canvas.png"/>')
          } else {
            // console.log(event.keyCode)
            $(".output_container").append('<img style="top:'+(i*10) +'px; left:20px;" class="waveform" id="'+key.charAt(i)+'" src="letters/'+key.charAt(i)+'_canvas.png"/>')
          }
      }
    }

    function flashNotSupported() {
        $(".not_supported").show().delay(500).fadeOut()
    }

    </script>
    <style media="screen">
      html body {
        background-color: black;
        margin:0;
        font-family: 'IBM Plex Sans', sans-serif;
        font-weight: 300;
        color:white;
      }

      h1 {
        /* margin-left: 20px; */
        font-size: 3em;
        font-weight: 300;
        /* margin-bottom: 0; */
      }

      h2 {
        /* margin-left: 20px; */
        font-weight: 500;
      }

      h3 {
        font-weight: 500;
      }

      div.header {
        padding:20px;
        background: white;
        color: black;
      }
      .input_container {
        margin:20px;
      }
      .output_container {
        width: 100%;
        display: block;
        position: relative;
        /* float: left; */
        height: 720px;
        background: black;
      }
      #input {
        position: relative;
        z-index: 2;
        width: calc(100% - 22px);
        padding: 10px;
        float:left;
        margin: 10px 0;
      }
      .waveform {
        position: absolute;
        max-width: 1000px;
      }
      .description {
        color: white;
      }
      .not_supported {
        background: red;
        position: relative;
        float: left;
        padding: 8px;
        margin-left: 20px;
        display: none;
        z-index: 100;
      }
      .project_writeup {
        padding:20px;
        background: white;
        color: black;
      }
      .writeup_copy {
        max-width: 704px;
      }
      .writeup_image {
        max-width: 100%;
        margin: 20px 0;
      }
    </style>
  </head>
  <body>
    <div class="header">
      <h1>Joy Vazirani</h1>
      <div class="writeup_copy">
        Fifty years ago this month, the first radio pulsar was discovered, known as <a href="https://en.wikipedia.org/wiki/PSR_B1919%2B21" target="
        ">CP 1919</a>. The signal was significant for many reasons, including being thought to be an extraterrestrial beacon. But for me, the significance of the CP 1919 is it's eventual use in the album artwork for Joy Division's <a href="https://en.wikipedia.org/wiki/Unknown_Pleasures" target="_blank">Unknown Pleasures</a>. It is one of the most beautiful and recognizable visual adaptations of scientific data.¬†
        <br>
        <br>
        To honor that legacy, you can create a similar image by typing in the box below, but instead of using pulsar data, it uses data from a quantum computer.
      </div>
    </div>
    <div class="input_container">
      <div class="description">
        Type any word (limited to letters)
      </div>
      <input id="input" type="text" name="type_text">
      <div class="not_supported">
        Character not supported
      </div>
    </div>
    <div class="output_container">
      <!-- All the goodies go here -->
    </div>
    <div class="project_writeup">
      <h1>Project Summary</h1>
      <div class="writeup_copy">
        The above demo creates an image with a quantum computer. Even better, the image is a word written by a quantum computer. Each line shows the amplitude of the binary representation of a letter of as an output of the Bernstein-Vazirani algorithm.¬†
        <br>
        <br>
        Didn't understand that sentence? That's okay. Lets break it down and get into it.
        <br>
        <br>
        First, lets talk about how quantum computers work a little bit. I'm going to skip some of the fundamentals, as its been said many times by people much more knowledgeable than myself, like this video. For our purposes here, the important part is that unlike regular (or classical) computers, quantum computers are probabilistic. Every time a quantum computer runs an algorithm, there is a probability of getting the correct answer, so quantum algorithms are written in such a way that the "right" answer is amplified when run many times. For example, a typical result from a quantum computer looks something like this.¬†
        <img class="writeup_image" src="images/histogram1.png" alt="Image of data from a quantum computer displayed as a histogram">
        Whatever the quantum computer was trying to compute, we can see that the right answer is that tall column in the middle. All those other little bars in our histogram are a result noise. Today's quantum computers aren't perfect, so there will be noise in our results. Remember, quantum computers are probabilistic, so incorrect answers will occasionally happen, but in this case, our correct answer is still fairly clear.
        <br>
        <br>
        So what is it calculating, and what is the answer? Lets add some more data to our histogram.
        <img class="writeup_image" src="images/histogram1.png" alt="Image of data from a quantum computer displayed as a histogram">
        As you can see, each bar is labeled with a series of 0s and 1s. These are 7 bit binary strings, and our amplified answer is "1010001", which is binary for the letter "Q". As you can see, our quantum computer is amplifying the letter Q, the first letter of Qiskit, which is exactly what we want! (For those really paying attention, text to binary is often written as 8 bits, starting with a 0 or 0b, but more on that later in the FAQs).
        <br>
        <br>
        From here, I exported the data as a csv and styled it to look like a line from the famous album artwork using Apple Numbers and Adobe Illustrator. The amplitudes may look slightly different because the below image uses all the data provided by the quantum computer, while the above is just a summary.¬†
        <img class="writeup_image" src="images/Q.png" alt="Quantum computing data representing the letter "Q" styled like the Unknown Pleasures album artwork.">
        <h2>How did the quantum computer "compute" the letter Q?</h2>
        That's where the Bernstein-Vazirani algorithm comes in which you can read all about it in depth here. And if you haven't picked up on it yet, I'm calling this "Joy Vazirani" because it styles the data from from the algorithm to look like the Joy Division artwork.¬†
        <br>
        <br>
        The Bernstein-Vazirani algorithm is a quantum algorithm that contains a black box, called an oracle, and can¬† query the oracle to obtain the solution. The oracle is a series of 0's and 1's, and the quantum computer returns the 0's and 1's as amplitudes. For our purposes, we encode the letters by first converting them to binary (0's and 1's) and then putting them into the oracle. We then ask the quantum computer to find the value of the oracle as a quantum state, which we then measure giving us our amplitudes as shown above.¬†
        <br>
        <br>
        The resulting circuit amplifies the quantum state that corresponds to our letter. To do a full word (or sentence), the same algorithm will need to be run for each letter. Which is why our "Qiskit" example has 6 lines, each corresponding to a letter of "Qiskit". In the interactive version here, I pre-ran every letter of the alphabet so you can play with it (26 letters, 26 circuits, 26 lines). And basically that's it! I certainly skimmed over some details, but the entire jupyter notebook can be found here, which builds upon the Qiskit implementation as described in the Qiskit textbook here. The primary difference from what is shown in the notebook is that you can enter a string of text, and it will return an array of circuits, corresponding to each letter. The array of circuits can be run all at once with Qiskit as one job, so give it a try!
        <br>
        <br>
        The source code for the web app is in the same repo here.
        <br>
        <br>
        For another example,¬† here is a mock up on a shirt that reads "qiskit terra aqua aer ignis".
        <img class="writeup_image" src="images/shirt.jpg" alt='Quantum computing data representing the letter "Q" styled like the Unknown Pleasures album artwork.'>

        <h2>Frequently asked questions</h2>
        <h3>Why the minor inaccuracies in the amplitudes?¬†</h3>
        Towards the beginning of the chapter on Bernstein-Vazirani, the Qiskit textbook says "Using a quantum computer, we can solve this problem with 100% confidence after only one call to the function ùëì(ùë•)." If that is the case, why are there any amplitudes other than the "correct" answer? This is because of noise in quantum systems which causes the little spikes. As an artist, I think that noise is beautiful and adds to the final effect. Once quantum computers are fully fault tolerant, this visual will be a lot more boring. For once, the noise is a good thing.
        <br>
        <br>
        <h3>Why are some letters more accurate than others?</h3>
        The circuit as it is created by the algorithm above is not the same circuit that gets sent to the actual quantum hardware. Each quantum computer available through IBM Quantum has its individual limitations. Not all qubits are entangled to every other qubit. And not every qubit performs equally. When a job gets sent to run, the circuit gets transpiled to fit on the hardware as efficiently as possible. But not all letters are equally efficient.
        <br>
        <br>
        In the example above, the circuits were run on "ibmq-paris", which the qubit connectivity looks like the following:
        <img class="writeup_image" src="images/connectivity.png" alt='Qubit connnetivity diagram for the quantum backend "ibmq-paris"'>
        When the circuit for "Q" was transpiled for this hardware, it looks like this:
        <img class="writeup_image" src="images/circuit1.png" alt='Transpiled circuit for the letter "Q"'>
        However, when the circuit for "k" was run, it was transpiled to look like this:
        <img class="writeup_image" src="images/circuit1.png" alt='Transpiled circuit for the letter "k"'>
        The second circuit is a fair bit longer (or as we say, has a greater depth), which makes it more difficult to maintain accuracy. The longer (in depth) a circuit is, the longer (in time) it takes to execute, which means more opportunity for noise to get into the system. Each letter looks a little different, so some letters will be less accurate than others.
        <h3>Why only 7 bits instead of 8 to represent a letter?</h3>
        The less bits used, the more accurate the result. When converting from text to binary in python, the data is prepended with "0b", which is just a computational way of saying "binary is about to follow". In my script I scrape both of these off. If you were to google an ascii to binary table, you would see all text starts with 0. Again, we don't need that, so I scrape it off. Like the above explanation about how circuit depth effects accuracy, so does the number of qubits used, called circuit width. At IBM, we take into consideration both circuit width and depth to account for accuracy, called quantum volume (or QV). For the web app implementation, I ran all circuits on the quantum computer call "ibmq_montreal" with the highest quantum volume, with QV64.


        <h2>Conclusion</h2>
        Quantum computing is difficult, but slowly becoming more accessible. It is usually done by scientists and researchers for, well, science and research. But at IBM we're trying to take quantum computing out of the lab and put it in the hands of everyone else with free cloud based tools like IBM Quantum Experience and open source tools like Qiskit. I work for IBM Quantum, but I'm also an artist and I want to show that quantum computers can be used by non-scientists to do things that won't necessarily advance the field of research, but are still valuable. I hope others like me, those without a quantum physics background but are curious and creative, can start learning quantum computing as a method of creative expression. I hope that this blog shows that quantum computing doesn't always have to be about solving the worlds most complex problems, and that those of us who aren't mathematicians can still learn to use quantum computers.
        <br>
        <br>
        To me, a quantum computer is a paintbrush. It's might be the worlds most complex paintbrush, but I hope this is the beginning of a learning path for using a quantum computer for creative expression.
      </div>

      </div>
    </div>
  </body>
</html>
